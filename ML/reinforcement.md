# ML - RL
|Title|Type|Conference|Remarks
|--|--|--|--|
|[SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient](https://arxiv.org/pdf/1609.05473.pdf)|Paper|ACL|Using RL to address discrete nature of token generation. Train GAN on top of RL, the policy net is the same as GAN's generator and Monte Carlo method is used to sample "future tokens" during G-training steps.|
|[A general reinforcement learning algorithm that masters chess, shogi, and Go through selfplay](https://kstatic.googleusercontent.com/files/2f51b2a749a284c2e2dfa13911da965f4855092a179469aedd15fbe4efe8f8cbf9c515ef83ac03a6515fa990e6f85fd827dcd477845e806f23a17845072dc7bd)|Paper|Science|As name suggested|
|[Playing Atari with Deep Reinforcement Learning](https://arxiv.org/abs/1312.5602)|Paper|.|famous atari paper
|[A Deep Reinforced Model for Abstractive Summarization](https://arxiv.org/pdf/1705.04304.pdf)|Paper|EMNLP|Address exposure bias with MRT (not sure why author claims this to be RL...)
|[Deep Reinforcement Learning for Dialogue Generation](https://arxiv.org/pdf/1606.01541.pdf)|Paper|ACL|Learn two agents to generate dialog
|[Active Object Localization with Deep Reinforcement Learning](https://arxiv.org/pdf/1511.06015.pdf)|Paper|ICCV|Frame object detection as MDP process with action as simple transformation on the bounding box


[Back to index](../README.md)